Image Classification using Vision Transformers (ViT) on CIFAR-10 Dataset
•	Developed a robust image recognition system for the CIFAR-10 dataset (60,000 images across 10 classes) using Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs). 
•	Designed and trained custom CNN architectures using TensorFlow, achieving up to 74.68% accuracy with a custom CNN model (19,049,546 parameters). 
•	Conducted comprehensive evaluations using metrics such as accuracy, precision, recall, and F-1 scores, highlighting strengths and areas for improvement. Notable accuracy: CNN (78%), LeNet (64.069% accuracy) and AlexNet (60.199% accuracy) architectures. 
•	Developed ViT models with PyTorch, leveraging self-attention mechanisms, and configured and trained a custom ViT model (2,859,274 parameters) achieving 51.26% accuracy. 
•	Utilized pre-trained ViT models from Hugging Face, achieving up to 94% accuracy.
•	Applied batch normalization, dropout, and kernel regularization across CNN and ViT models to prevent overfitting and enhance robustness including configurations for AlexNet with batch normalization, dropout 0.5, kernel regularizer 12 0.002. 
•	LeNet with batch normalization, dropout 0.5, kernel regularizer 12 0.001, and custom CNN with batch normalization, dropout 0.4, kernel regularizer 12 0.001. 
